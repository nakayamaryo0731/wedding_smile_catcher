"""
Wedding Smile Catcher - Scoring Function
Analyzes uploaded images using:
- Vision API for smile detection (face count + joy likelihood)
- Vertex AI (Gemini) for theme evaluation (0-100 score + comment)
- Average Hash for similarity detection (prevents spam uploads)
"""

import os
import logging
import random
import json
import time
import io
from typing import Dict, Any, List
import uuid
from concurrent.futures import ThreadPoolExecutor

import functions_framework
from flask import Request, jsonify
from linebot import LineBotApi
from linebot.models import TextSendMessage
from linebot.exceptions import LineBotApiError
from google.cloud import firestore, storage, vision
from google.cloud import logging as cloud_logging
import vertexai
from vertexai.generative_models import GenerativeModel, Part
from PIL import Image as PILImage
import imagehash

# Initialize Cloud Logging
logging_client = cloud_logging.Client()
logging_client.setup_logging()

# Initialize logger with Cloud Logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# Initialize Google Cloud clients
db = firestore.Client()
storage_client = storage.Client()
vision_client = vision.ImageAnnotatorClient()

# Environment variables
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get("LINE_CHANNEL_ACCESS_TOKEN")
GCP_PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "wedding-smile-catcher")
GCP_REGION = os.environ.get("GCP_REGION", "asia-northeast1")
STORAGE_BUCKET = os.environ.get("STORAGE_BUCKET", "wedding-smile-images")
CURRENT_EVENT_ID = os.environ.get("CURRENT_EVENT_ID", "test")

# Initialize LINE Bot API
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)

# Initialize Vertex AI
vertexai.init(project=GCP_PROJECT_ID, location=GCP_REGION)


@functions_framework.http
def scoring(request: Request):
    """
    Cloud Functions HTTP entrypoint for scoring.

    Analyzes uploaded images using Vision API for smile detection.
    Calculates scores and sends results back to LINE Bot.

    Args:
        request: Flask Request object with image_id and user_id

    Returns:
        JSON response with scoring results
    """
    # Generate request ID for tracing
    request_id = str(uuid.uuid4())

    # Parse request
    request_json = request.get_json(silent=True)

    if not request_json:
        logger.warning("No JSON body provided", extra={"request_id": request_id})
        return jsonify({"error": "No JSON body provided"}), 400

    image_id = request_json.get("image_id")
    user_id = request_json.get("user_id")

    if not image_id or not user_id:
        logger.warning(
            "Missing required parameters",
            extra={"request_id": request_id, "image_id": image_id, "user_id": user_id},
        )
        return jsonify({"error": "Missing image_id or user_id"}), 400

    # Structured logging with context
    logger.info(
        "Scoring request received",
        extra={
            "request_id": request_id,
            "image_id": image_id,
            "user_id": user_id,
            "event": "scoring_started",
        },
    )

    start_time = time.time()

    try:
        # Generate scores using Vision API
        scores = generate_scores_with_vision_api(image_id, request_id)

        # Update Firestore
        update_firestore(image_id, user_id, scores)

        # Send result to LINE
        send_result_to_line(user_id, scores)

        elapsed_time = time.time() - start_time

        # Success log with metrics
        logger.info(
            "Scoring completed successfully",
            extra={
                "request_id": request_id,
                "image_id": image_id,
                "user_id": user_id,
                "total_score": scores.get("total_score"),
                "elapsed_time": round(elapsed_time, 2),
                "event": "scoring_completed",
            },
        )

        # Return success response
        return (
            jsonify(
                {
                    "status": "success",
                    "image_id": image_id,
                    "scores": scores,
                    "request_id": request_id,
                }
            ),
            200,
        )

    except Exception as e:
        elapsed_time = time.time() - start_time

        logger.error(
            "Scoring failed",
            extra={
                "request_id": request_id,
                "image_id": image_id,
                "user_id": user_id,
                "error": str(e),
                "error_type": type(e).__name__,
                "elapsed_time": round(elapsed_time, 2),
                "event": "scoring_failed",
            },
            exc_info=True,
        )

        # Try to send error message to user
        try:
            send_error_to_line(user_id)
        except Exception:
            pass

        return (
            jsonify(
                {
                    "status": "error",
                    "error": str(e),
                    "image_id": image_id,
                    "request_id": request_id,
                }
            ),
            500,
        )


def get_joy_likelihood_score(joy_likelihood) -> float:
    """
    Convert joy likelihood enum to numeric score.

    Args:
        joy_likelihood: Vision API joy likelihood enum

    Returns:
        Numeric score (0-95)
    """
    likelihood_map = {
        vision.Likelihood.VERY_LIKELY: 95.0,
        vision.Likelihood.LIKELY: 75.0,
        vision.Likelihood.POSSIBLE: 50.0,
        vision.Likelihood.UNLIKELY: 25.0,
        vision.Likelihood.VERY_UNLIKELY: 5.0,
        vision.Likelihood.UNKNOWN: 0.0,
    }
    return likelihood_map.get(joy_likelihood, 0.0)


def calculate_smile_score(image_bytes: bytes) -> Dict[str, Any]:
    """
    Calculate smile score using Vision API.
    Implements exponential backoff retry for rate limit and server errors.

    Args:
        image_bytes: Image binary data

    Returns:
        Dictionary with smile_score and face_count
    """
    # Retry configuration
    max_retries = 3
    base_delay = 1.0  # seconds
    max_delay = 10.0  # seconds

    for attempt in range(max_retries):
        try:
            # Create Vision API image object
            image = vision.Image(content=image_bytes)

            # Detect faces
            response = vision_client.face_detection(image=image)

            if response.error.message:
                raise Exception(f"Vision API error: {response.error.message}")

            # Calculate total smile score
            total_smile_score = 0.0
            smiling_faces = 0

            for face in response.face_annotations:
                # Only count faces with LIKELY or VERY_LIKELY joy
                if face.joy_likelihood >= vision.Likelihood.LIKELY:
                    score = get_joy_likelihood_score(face.joy_likelihood)
                    total_smile_score += score
                    smiling_faces += 1
                    logger.info(
                        f"Face detected: joy={face.joy_likelihood.name}, score={score}"
                    )

            face_count = len(response.face_annotations)

            logger.info(
                f"Smile detection complete: {smiling_faces}/{face_count} smiling faces, "
                f"total score={total_smile_score}"
            )

            return {
                "smile_score": round(total_smile_score, 2),
                "face_count": face_count,
                "smiling_faces": smiling_faces,
            }

        except Exception as e:
            error_message = str(e)
            logger.warning(
                f"Vision API error (attempt {attempt + 1}/{max_retries}): {error_message}"
            )

            # Check if error is retryable (rate limit or server error)
            is_retryable = (
                "429" in error_message  # Rate limit
                or "500" in error_message  # Internal server error
                or "502" in error_message  # Bad gateway
                or "503" in error_message  # Service unavailable
                or "504" in error_message  # Gateway timeout
                or "ResourceExhausted" in error_message
                or "DeadlineExceeded" in error_message
            )

            # If not retryable or last attempt, return fallback
            if not is_retryable or attempt == max_retries - 1:
                logger.error(f"Vision API error (final): {error_message}")
                # Return zero score to ensure fairness - API failures should not give any points
                return {
                    "smile_score": 0.0,  # Zero points for API failures
                    "face_count": 0,
                    "smiling_faces": 0,
                    "error": "vision_api_failed",
                }

            # Calculate exponential backoff delay with jitter
            delay = min(base_delay * (2**attempt), max_delay)
            jitter = random.uniform(0, delay * 0.1)  # Add 10% jitter
            sleep_time = delay + jitter

            logger.info(f"Retrying Vision API after {sleep_time:.2f} seconds...")
            time.sleep(sleep_time)

    # Should not reach here, but return fallback just in case
    return {
        "smile_score": 300.0,
        "face_count": 3,
        "smiling_faces": 3,
        "error": "vision_api_failed",
    }


def download_image_from_storage(storage_path: str) -> bytes:
    """
    Download image from Cloud Storage.

    Args:
        storage_path: Path to image in Cloud Storage bucket

    Returns:
        Image binary data
    """
    try:
        bucket = storage_client.bucket(STORAGE_BUCKET)
        blob = bucket.blob(storage_path)
        image_bytes = blob.download_as_bytes()

        logger.info(f"Downloaded image from Storage: {storage_path}")
        return image_bytes

    except Exception as e:
        logger.error(f"Failed to download image: {str(e)}")
        raise


def calculate_average_hash(image_bytes: bytes) -> str:
    """
    Calculate Average Hash for similarity detection.

    Args:
        image_bytes: Image binary data

    Returns:
        str: 64-bit hash value as hexadecimal string
    """
    try:
        img = PILImage.open(io.BytesIO(image_bytes))
        hash_value = imagehash.average_hash(img, hash_size=8)
        hash_str = str(hash_value)

        logger.info(f"Calculated average hash: {hash_str}")
        return hash_str

    except Exception as e:
        logger.error(f"Failed to calculate average hash: {str(e)}")
        # Return a random hash as fallback to avoid blocking the process
        return f"error_{random.randint(1000, 9999)}"


def is_similar_image(
    new_hash: str, existing_hashes: List[str], threshold: int = 8
) -> bool:
    """
    Check if the image is similar to any existing images.

    Args:
        new_hash: Hash of the new image
        existing_hashes: List of hashes from existing images
        threshold: Hamming distance threshold (default: 8)

    Returns:
        bool: True if similar image exists
    """
    # Skip similarity check if new hash is an error hash
    if new_hash.startswith("error_"):
        logger.warning("Skipping similarity check due to hash calculation error")
        return False

    try:
        new_hash_obj = imagehash.hex_to_hash(new_hash)

        for existing_hash in existing_hashes:
            # Skip error hashes
            if existing_hash.startswith("error_"):
                continue

            try:
                existing_hash_obj = imagehash.hex_to_hash(existing_hash)
                hamming_distance = new_hash_obj - existing_hash_obj

                logger.info(
                    f"Comparing hashes: new={new_hash}, existing={existing_hash}, "
                    f"distance={hamming_distance}"
                )

                if hamming_distance <= threshold:
                    logger.warning(
                        f"Similar image detected! Distance={hamming_distance} <= {threshold}"
                    )
                    return True

            except Exception as e:
                logger.error(f"Error comparing hash {existing_hash}: {str(e)}")
                continue

        logger.info(f"No similar images found (checked {len(existing_hashes)} hashes)")
        return False

    except Exception as e:
        logger.error(f"Error in similarity check: {str(e)}")
        # On error, assume not similar to avoid blocking uploads
        return False


def get_existing_hashes_for_user(user_id: str) -> List[str]:
    """
    Get all existing average hashes for a user's uploaded images in the current event.

    Args:
        user_id: User ID

    Returns:
        List of average hash strings
    """
    try:
        # Query images collection for this user in current event with status 'completed'
        images_query = (
            db.collection("images")
            .where("event_id", "==", CURRENT_EVENT_ID)
            .where("user_id", "==", user_id)
            .where("status", "==", "completed")
            .get()
        )

        hashes = []
        for doc in images_query:
            data = doc.to_dict()
            if "average_hash" in data:
                hashes.append(data["average_hash"])

        logger.info(f"Retrieved {len(hashes)} existing hashes for user {user_id}")
        return hashes

    except Exception as e:
        logger.error(f"Failed to get existing hashes: {str(e)}")
        # Return empty list on error to avoid blocking the process
        return []


def evaluate_theme(image_bytes: bytes) -> Dict[str, Any]:
    """
    Evaluate image theme relevance using Vertex AI (Gemini).
    Implements exponential backoff retry for rate limit and server errors.

    Args:
        image_bytes: Image binary data

    Returns:
        Dictionary with score (0-100) and comment
    """
    prompt = """
„ÅÇ„Å™„Åü„ÅØÁµêÂ©öÂºèÂÜôÁúü„ÅÆÂ∞ÇÈñÄÂÆ∂„Åß„Åô„ÄÇÊèê‰æõ„Åï„Çå„ÅüÂÜôÁúü„ÇíÂàÜÊûê„Åó„ÄÅ‰ª•‰∏ã„ÅÆÂü∫Ê∫ñ„Å´Âæì„Å£„Å¶Á¨ëÈ°î„ÅÆË©ï‰æ°„ÇíË°å„Å£„Å¶„Åè„Å†„Åï„ÅÑÔºö

## ÂàÜÊûêÂØæË±°
- Êñ∞ÈÉéÊñ∞Â©¶„Çí‰∏≠ÂøÉ„Å´„ÄÅÂÜôÁúü„Å´ÂÜô„Å£„Å¶„ÅÑ„ÇãÂÖ®„Å¶„ÅÆ‰∫∫Áâ©„ÅÆË°®ÊÉÖ„ÇíË©ï‰æ°
- „Ç∞„É´„Éº„Éó„Ç∑„Éß„ÉÉ„Éà„ÅÆÂ†¥Âêà„ÅØ„ÄÅÂÖ®‰ΩìÁöÑ„Å™Èõ∞Âõ≤Ê∞ó„ÇÇËÄÉÊÖÆ

## Ë©ï‰æ°Âü∫Ê∫ñÔºà100ÁÇπÊ∫ÄÁÇπÔºâ
1. Ëá™ÁÑ∂„ÅïÔºà30ÁÇπÔºâ
   - ‰Ωú„ÇäÁ¨ë„ÅÑ„Åß„ÅØ„Å™„Åè„ÄÅËá™ÁÑ∂„Å™Ë°®ÊÉÖ„Åã„Å©„ÅÜ„Åã
   - Á∑äÂºµ„ÅåÊÑü„Åò„Çâ„Çå„Åö„ÄÅ„É™„É©„ÉÉ„ÇØ„Çπ„Åó„Å¶„ÅÑ„Çã„Åã
   - ÁõÆÂÖÉ„ÅÆË°®ÊÉÖ„ÅåËá™ÁÑ∂„Åã

2. Âπ∏Á¶èÂ∫¶Ôºà40ÁÇπÔºâ
   - Á¥îÁ≤ã„Å™Âñú„Å≥„ÅåË°®Áèæ„Åï„Çå„Å¶„ÅÑ„Çã„Åã
   - ÁõÆ„ÅåÁ¨ë„Å£„Å¶„ÅÑ„Çã„ÅãÔºà„ÇØ„É≠„Éº„Ç∫„Éâ„Çπ„Éû„Ç§„É´Ôºâ
   - Ê≠Ø„ÅåË¶ã„Åà„ÇãÁ®ãÂ∫¶„ÅÆÈÅ©Â∫¶„Å™Á¨ëÈ°î„Åã

3. Âë®Âõ≤„Å®„ÅÆË™øÂíåÔºà30ÁÇπÔºâ
   - Âë®„Çä„ÅÆ‰∫∫„ÄÖ„Å®Á¨ëÈ°î„ÅåË™øÂíå„Åó„Å¶„ÅÑ„Çã„Åã
   - Â†¥Èù¢„Å´Áõ∏Âøú„Åó„ÅÑË°®ÊÉÖ„ÅÆÂ§ß„Åç„Åï„Åã
   - „Ç∞„É´„Éº„ÉóÂÖ®‰Ωì„ÅßÁµ±‰∏ÄÊÑü„ÅÆ„ÅÇ„ÇãÈõ∞Âõ≤Ê∞ó„ÅåÂá∫„Å¶„ÅÑ„Çã„Åã

## Êé°ÁÇπÊñπÊ≥ï
„Ç≥„É°„É≥„Éà„Å´„Å§„ÅÑ„Å¶Ôºö
- ÂÖ∑‰ΩìÁöÑ„Å™ÊîπÂñÑÁÇπ„Åå„ÅÇ„Çå„Å∞ÊèêÊ°à
- Áâπ„Å´ÂÑ™„Çå„Å¶„ÅÑ„ÇãÁÇπ„ÅØÂº∑Ë™ø

## Ê≥®ÊÑè‰∫ãÈ†Ö
- ÊñáÂåñÁöÑËÉåÊôØ„ÇÑÁµêÂ©öÂºè„ÅÆ„Çπ„Çø„Ç§„É´„ÇíËÄÉÊÖÆ
- Âê¶ÂÆöÁöÑ„Å™Ë°®Áèæ„ÅØÈÅø„Åë„ÄÅÂª∫Ë®≠ÁöÑ„Å™„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØ„ÇíÂøÉ„Åå„Åë„Çã
- „Éó„É©„Ç§„Éê„Ç∑„Éº„Å´ÈÖçÊÖÆ„Åó„ÅüË°®Áèæ„Çí‰ΩøÁî®

## Âá∫Âäõ
JSONÂΩ¢Âºè„Åßscore„Å®comment„ÅÆ„Ç≠„Éº„ÅßËøîÂç¥„Åô„Çã„ÄÇJSON„ÅÆ„Åø„ÇíÂá∫Âäõ„Åô„Çã„Åì„Å®„ÄÇ

‰æã:
{
  "score": 85,
  "comment": "Êñ∞ÈÉéÊñ∞Â©¶„ÅÆÁõÆÂÖÉ„Åã„ÇâÊ∫¢„Çå„ÇãËá™ÁÑ∂„Å™Âñú„Å≥„ÅåÂç∞Ë±°ÁöÑ„Åß„ÄÅÂë®Âõ≤„ÅÆÂèÇÂàóËÄÖ„Å®„ÅÆ‰∏Ä‰ΩìÊÑü„ÇÇÁ¥†Êô¥„Çâ„Åó„ÅÑ"
}
"""

    # Retry configuration
    max_retries = 3
    base_delay = 1.0  # seconds
    max_delay = 10.0  # seconds

    for attempt in range(max_retries):
        try:
            # Initialize Gemini model (using latest Flash model)
            model = GenerativeModel("gemini-2.5-flash")

            # Create image part from bytes
            image_part = Part.from_data(image_bytes, mime_type="image/jpeg")

            # Generate content
            response = model.generate_content([image_part, prompt])

            logger.info(f"Gemini response: {response.text}")

            # Parse JSON response
            # Remove markdown code blocks if present
            response_text = response.text.strip()
            if response_text.startswith("```json"):
                response_text = response_text[7:]  # Remove ```json
            if response_text.startswith("```"):
                response_text = response_text[3:]  # Remove ```
            if response_text.endswith("```"):
                response_text = response_text[:-3]  # Remove ```
            response_text = response_text.strip()

            result = json.loads(response_text)

            # Validate response structure
            if "score" not in result or "comment" not in result:
                raise ValueError("Invalid response format from Gemini")

            # Ensure score is an integer
            result["score"] = int(result["score"])

            logger.info(
                f"Theme evaluation complete: score={result['score']}, "
                f"comment={result['comment'][:50]}..."
            )

            return result

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Gemini response as JSON: {str(e)}")
            if "response" in locals():
                logger.error(f"Response text: {response.text}")
            # JSON parse errors are not retryable
            return {
                "score": 50,
                "comment": "AIË©ï‰æ°„ÅÆËß£Êûê„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„Éá„Éï„Ç©„É´„Éà„Çπ„Ç≥„Ç¢„ÇíÈÅ©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
                "error": "vertex_ai_parse_failed",
            }

        except Exception as e:
            error_message = str(e)
            logger.warning(
                f"Gemini API error (attempt {attempt + 1}/{max_retries}): {error_message}"
            )

            # Check if error is retryable (rate limit or server error)
            is_retryable = (
                "429" in error_message  # Rate limit
                or "500" in error_message  # Internal server error
                or "502" in error_message  # Bad gateway
                or "503" in error_message  # Service unavailable
                or "504" in error_message  # Gateway timeout
                or "ResourceExhausted" in error_message
                or "DeadlineExceeded" in error_message
            )

            # If not retryable or last attempt, return fallback
            if not is_retryable or attempt == max_retries - 1:
                logger.error(f"Gemini API error (final): {error_message}")
                return {
                    "score": 50,
                    "comment": "AIË©ï‰æ°‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ„Éá„Éï„Ç©„É´„Éà„Çπ„Ç≥„Ç¢„ÇíÈÅ©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
                    "error": "vertex_ai_failed",
                }

            # Calculate exponential backoff delay with jitter
            delay = min(base_delay * (2**attempt), max_delay)
            jitter = random.uniform(0, delay * 0.1)  # Add 10% jitter
            sleep_time = delay + jitter

            logger.info(f"Retrying after {sleep_time:.2f} seconds...")
            time.sleep(sleep_time)

    # Should not reach here, but return fallback just in case
    return {
        "score": 50,
        "comment": "AIË©ï‰æ°‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ„Éá„Éï„Ç©„É´„Éà„Çπ„Ç≥„Ç¢„ÇíÈÅ©Áî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ",
        "error": "vertex_ai_failed",
    }


def generate_scores_with_vision_api(image_id: str, request_id: str) -> Dict[str, Any]:
    """
    Generate scores using Vision API for smile detection, Vertex AI for theme evaluation,
    and Average Hash for similarity detection.

    Uses parallel processing for Vision API, Vertex AI, and Average Hash calculations
    to reduce total processing time.

    Args:
        image_id: Image document ID in Firestore
        request_id: Request ID for tracing

    Returns:
        Dictionary with scoring data
    """
    log_context = {"request_id": request_id, "image_id": image_id}

    # Get image document from Firestore
    image_ref = db.collection("images").document(image_id)
    image_doc = image_ref.get()

    if not image_doc.exists:
        raise Exception(f"Image document not found: {image_id}")

    image_data = image_doc.to_dict()
    storage_path = image_data.get("storage_path")
    user_id = image_data.get("user_id")

    if not storage_path:
        raise Exception(f"Storage path not found in image document: {image_id}")

    if not user_id:
        raise Exception(f"User ID not found in image document: {image_id}")

    log_context["user_id"] = user_id

    # Download image from Cloud Storage
    download_start = time.time()
    image_bytes = download_image_from_storage(storage_path)
    download_time = time.time() - download_start

    logger.info(
        "Image downloaded from storage",
        extra={
            **log_context,
            "elapsed_time": round(download_time, 2),
            "event": "image_downloaded",
        },
    )

    # Execute Vision API, Vertex AI, and Average Hash calculations in parallel
    logger.info(
        "Starting parallel API processing",
        extra={**log_context, "event": "parallel_processing_start"},
    )
    start_time = time.time()

    with ThreadPoolExecutor(max_workers=3) as executor:
        # Submit all three tasks
        vision_future = executor.submit(calculate_smile_score, image_bytes)
        theme_future = executor.submit(evaluate_theme, image_bytes)
        hash_future = executor.submit(calculate_average_hash, image_bytes)

        # Wait for all tasks to complete
        vision_result = vision_future.result()
        theme_result = theme_future.result()
        average_hash = hash_future.result()

    elapsed_time = time.time() - start_time

    smile_score = vision_result["smile_score"]
    face_count = vision_result["face_count"]
    vision_error = vision_result.get("error")

    ai_score = theme_result["score"]
    ai_comment = theme_result["comment"]
    ai_error = theme_result.get("error")

    logger.info(
        "Parallel API processing completed",
        extra={
            **log_context,
            "smile_score": smile_score,
            "face_count": face_count,
            "ai_score": ai_score,
            "elapsed_time": round(elapsed_time, 2),
            "event": "parallel_processing_completed",
        },
    )

    # Get existing hashes for this user
    existing_hashes = get_existing_hashes_for_user(user_id)

    # Check if similar image exists
    is_similar = is_similar_image(average_hash, existing_hashes, threshold=8)

    logger.info(
        "Similarity check completed",
        extra={
            **log_context,
            "is_similar": is_similar,
            "existing_hashes_count": len(existing_hashes),
            "event": "similarity_check_completed",
        },
    )

    # Calculate penalty
    penalty = 0.33 if is_similar else 1.0

    # Calculate total score
    total_score = round((smile_score * ai_score / 100) * penalty, 2)

    # Build comment with error warnings if any
    error_warnings = []
    if vision_error:
        logger.warning(f"Vision API error occurred: {vision_error}")
        error_warnings.append(
            "‚ö†Ô∏è Á¨ëÈ°îÊ§úÂá∫„Åß„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇÊé®ÂÆöÂÄ§„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ"
        )
    if ai_error:
        logger.warning(f"Vertex AI error occurred: {ai_error}")
        error_warnings.append(
            "‚ö†Ô∏è AIË©ï‰æ°„Åß„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇ„Éá„Éï„Ç©„É´„ÉàÂÄ§„Çí‰ΩøÁî®„Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ"
        )

    if error_warnings:
        warning_text = "\n".join(error_warnings)
        comment = (
            f"{warning_text}\n\n"
            f"{ai_comment}\n\n"
            f"Á¨ëÈ°îÊ§úÂá∫: {vision_result.get('smiling_faces', face_count)}‰∫∫/{face_count}‰∫∫„ÅåÁ¨ëÈ°î„Åß„ÅôÔºÅ"
        )
    else:
        comment = (
            f"{ai_comment}\n\n"
            f"Á¨ëÈ°îÊ§úÂá∫: {vision_result['smiling_faces']}‰∫∫/{face_count}‰∫∫„ÅåÁ¨ëÈ°î„Åß„ÅôÔºÅ"
        )

    result = {
        "smile_score": smile_score,
        "ai_score": ai_score,
        "total_score": total_score,
        "comment": comment,
        "face_count": face_count,
        "is_similar": is_similar,
        "average_hash": average_hash,
    }

    # Add error flags if any occurred
    if vision_error or ai_error:
        result["has_errors"] = True
        if vision_error:
            result["vision_error"] = vision_error
        if ai_error:
            result["ai_error"] = ai_error
        logger.error(
            "Scoring completed with errors",
            extra={
                **log_context,
                "total_score": total_score,
                "penalty_applied": is_similar,
                "vision_error": vision_error,
                "ai_error": ai_error,
                "event": "score_calculated_with_errors",
            },
        )
    else:
        logger.info(
            "Scoring completed successfully",
            extra={
                **log_context,
                "total_score": total_score,
                "penalty_applied": is_similar,
                "event": "score_calculated",
            },
        )

    return result


def generate_dummy_scores() -> Dict[str, Any]:
    """
    Generate dummy scores for testing.
    This function is kept for backwards compatibility.

    Returns:
        Dictionary with dummy score data
    """
    # Random dummy values
    smile_score = round(random.uniform(300, 500), 2)
    ai_score = random.randint(70, 95)
    face_count = random.randint(3, 7)
    is_similar = random.choice([True, False])

    # Calculate penalty
    penalty = 0.33 if is_similar else 1.0

    # Calculate total score
    total_score = round((smile_score * ai_score / 100) * penalty, 2)

    return {
        "smile_score": smile_score,
        "ai_score": ai_score,
        "total_score": total_score,
        "comment": "„Åì„Çå„ÅØ„ÉÄ„Éü„Éº„ÅÆ„Çπ„Ç≥„Ç¢„É™„É≥„Ç∞ÁµêÊûú„Åß„Åô„ÄÇÂÆüË£ÖÂÆå‰∫ÜÂæå„ÅØÂÆüÈöõ„ÅÆAIË©ï‰æ°„Å´ÁΩÆ„ÅçÊèõ„Çè„Çä„Åæ„Åô„ÄÇ",
        "face_count": face_count,
        "is_similar": is_similar,
        "average_hash": "dummy_hash_" + str(random.randint(1000, 9999)),
    }


def update_firestore(image_id: str, user_id: str, scores: Dict[str, Any]):
    """
    Update Firestore with scoring results.

    Args:
        image_id: Image document ID
        user_id: User ID
        scores: Scoring results

    Raises:
        Exception: If Firestore update fails
    """
    try:
        # Update image document
        image_ref = db.collection("images").document(image_id)
        image_ref.update(
            {
                "smile_score": scores["smile_score"],
                "ai_score": scores["ai_score"],
                "total_score": scores["total_score"],
                "comment": scores["comment"],
                "average_hash": scores["average_hash"],
                "is_similar": scores["is_similar"],
                "face_count": scores["face_count"],
                "status": "completed",
                "scored_at": firestore.SERVER_TIMESTAMP,
            }
        )

        logger.info(f"Successfully updated image document: {image_id}")

    except Exception as e:
        logger.error(
            f"Failed to update image document {image_id}: {str(e)}", exc_info=True
        )
        raise

    # Update user statistics with transaction for concurrency safety
    try:
        user_ref = db.collection("users").document(user_id)
        transaction = db.transaction()
        _update_user_stats_in_transaction(transaction, user_ref, scores["total_score"])
        logger.info(f"Successfully updated user stats: {user_id}")

    except Exception as e:
        logger.error(
            f"Failed to update user stats for {user_id}: {str(e)}", exc_info=True
        )
        # Don't raise - image update succeeded, user stats update is secondary
        # This will be logged for monitoring but won't fail the entire function


@firestore.transactional
def _update_user_stats_in_transaction(transaction, user_ref, new_score: float):
    """
    Update user statistics with transaction to prevent race conditions.

    Args:
        transaction: Firestore transaction
        user_ref: User document reference
        new_score: New score to compare with best_score
    """
    user_doc = user_ref.get(transaction=transaction)

    if not user_doc.exists:
        logger.warning(f"User document not found: {user_ref.id}")
        return

    user_data = user_doc.to_dict()
    current_best = user_data.get("best_score", 0)
    new_best = max(current_best, new_score)

    transaction.update(
        user_ref, {"total_uploads": firestore.Increment(1), "best_score": new_best}
    )


def _send_line_message_with_retry(line_user_id: str, message, max_retries: int = 3):
    """
    Send LINE message with retry logic for transient failures.

    Args:
        line_user_id: LINE user ID
        message: LINE message object
        max_retries: Maximum number of retry attempts (default: 3)
    """
    for attempt in range(max_retries):
        try:
            line_bot_api.push_message(line_user_id, message)
            logger.info(f"Successfully sent message to LINE user: {line_user_id}")
            return

        except LineBotApiError as e:
            is_last_attempt = attempt == max_retries - 1

            # Check if error is retryable (5xx server errors or rate limit)
            is_retryable = (
                500 <= e.status_code < 600  # Server errors
                or e.status_code == 429  # Rate limit
            )

            if is_retryable and not is_last_attempt:
                wait_time = 2**attempt  # Exponential backoff: 1s, 2s, 4s
                logger.warning(
                    f"LINE API error {e.status_code}, retrying in {wait_time}s "
                    f"(attempt {attempt + 1}/{max_retries}): {e.message}"
                )
                time.sleep(wait_time)
                continue

            # Non-retryable error or final attempt
            logger.error(
                f"LINE API error (final, status={e.status_code}): {e.message}",
                exc_info=True,
            )
            return

        except Exception as e:
            is_last_attempt = attempt == max_retries - 1

            if not is_last_attempt:
                wait_time = 2**attempt
                logger.warning(
                    f"Failed to send LINE message, retrying in {wait_time}s "
                    f"(attempt {attempt + 1}/{max_retries}): {str(e)}"
                )
                time.sleep(wait_time)
                continue

            logger.error(
                f"Failed to send LINE message after {max_retries} attempts: {str(e)}",
                exc_info=True,
            )
            return


def send_result_to_line(user_id: str, scores: Dict[str, Any]):
    """
    Send scoring result to LINE user.

    Args:
        user_id: User ID (Firestore document ID, not LINE user ID)
        scores: Scoring results
    """
    # Get user's LINE user ID
    user_ref = db.collection("users").document(user_id)
    user_doc = user_ref.get()

    if not user_doc.exists:
        logger.error(f"User not found: {user_id}")
        return

    user_data = user_doc.to_dict()
    line_user_id = user_data.get("line_user_id")

    if not line_user_id:
        logger.error(f"LINE user ID not found for user: {user_id}")
        return

    # Build message
    if scores["is_similar"]:
        message_text = (
            f"üì∏ „Çπ„Ç≥„Ç¢: {scores['total_score']}ÁÇπ\n\n"
            f"‚ö†Ô∏è „Åì„ÅÆÂÜôÁúü„ÅØ„ÄÅ‰ª•Ââç„ÅÆÊäïÁ®ø„Å®‰ºº„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n"
            f"ÈÄ£ÂÜô„Åß„ÅØ„Å™„Åè„ÄÅÈÅï„ÅÜÊßãÂõ≥„ÅßÊíÆÂΩ±„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜÔºÅ\n\n"
            f"üòä Á¨ëÈ°î„Çπ„Ç≥„Ç¢: {scores['smile_score']}ÁÇπÔºà{scores['face_count']}‰∫∫Ôºâ\n"
            f"ü§ñ AI„ÉÜ„Éº„ÉûË©ï‰æ°: {scores['ai_score']}ÁÇπ"
        )
    else:
        message_text = (
            f"üéâ Êé°ÁÇπÂÆå‰∫ÜÔºÅ\n\n"
            f"„ÄêÊúÄÁµÇ„Çπ„Ç≥„Ç¢„Äë{scores['total_score']}ÁÇπ\n\n"
            f"üòä Á¨ëÈ°î„Çπ„Ç≥„Ç¢: {scores['smile_score']}ÁÇπÔºà{scores['face_count']}‰∫∫Ôºâ\n"
            f"ü§ñ AI„ÉÜ„Éº„ÉûË©ï‰æ°: {scores['ai_score']}ÁÇπ\n"
            f"üí¨ {scores['comment']}"
        )

    # Send message with retry logic
    message = TextSendMessage(text=message_text)
    _send_line_message_with_retry(line_user_id, message)


def send_error_to_line(user_id: str):
    """
    Send error message to LINE user.

    Args:
        user_id: User ID
    """
    # Get user's LINE user ID
    user_ref = db.collection("users").document(user_id)
    user_doc = user_ref.get()

    if not user_doc.exists:
        return

    user_data = user_doc.to_dict()
    line_user_id = user_data.get("line_user_id")

    if not line_user_id:
        return

    message = TextSendMessage(
        text="‚ùå „Çπ„Ç≥„Ç¢„É™„É≥„Ç∞Âá¶ÁêÜ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ\n\n„ÇÇ„ÅÜ‰∏ÄÂ∫¶„ÅäË©¶„Åó„Åè„Å†„Åï„ÅÑ„ÄÇ"
    )
    _send_line_message_with_retry(line_user_id, message)
